{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Primer Experimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probaremos vectorizadores y clasificadores básicos sin tocar demasiado los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_datasets\n",
    "train, dev, test = load_datasets()\n",
    "X_train, y_train = train\n",
    "X_dev, y_dev = dev\n",
    "X_test, y_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer +  LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..., max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t1.00\tmacro f1\t1.00\n"
     ]
    }
   ],
   "source": [
    "from util import print_short_eval\n",
    "print_short_eval(pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.83      0.79      0.81       162\n",
      "        pos       0.77      0.80      0.78       138\n",
      "\n",
      "avg / total       0.80      0.80      0.80       300\n",
      "\n",
      "[[128  34]\n",
      " [ 27 111]]\n"
     ]
    }
   ],
   "source": [
    "from util import print_eval\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Bueno comienzo!\n",
    "\n",
    "Suficientemente bueno como para hacer evaluación final y guardar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.78\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.80      0.77      0.79       257\n",
      "        pos       0.77      0.80      0.78       243\n",
      "\n",
      "avg / total       0.78      0.78      0.78       500\n",
      "\n",
      "[[198  59]\n",
      " [ 49 194]]\n"
     ]
    }
   ],
   "source": [
    "print_eval(pipeline, X_test, y_test)\n",
    "from util import save_model\n",
    "save_model(pipeline, '2018-07-27_count_linearsvc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juguemos un Poco\n",
    "\n",
    "Probemos nuestro clasificador con ejemplos de juguete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie sucks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is very very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La repetición de palabras afecta bastante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1er Experimento: Binarizar Conteos\n",
    "\n",
    "Probemos con **binary=True** a ver si se arregla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.85      0.86      0.86       162\n",
      "        pos       0.84      0.82      0.83       138\n",
      "\n",
      "avg / total       0.84      0.84      0.84       300\n",
      "\n",
      "[[140  22]\n",
      " [ 25 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True)),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Muy bueno! De 80% a 84% en un solo cambio.\n",
    "\n",
    "Veamos si se arreglaron los ejemplos de juguete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is very good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is very bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['this movie is not bad, it is good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá hay un problema con la negación, y con la pérdida de información del orden de las palabras.\n",
    "\n",
    "¿Qué se puede hacer con esto? **¡Ejercicio!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizamos el experimento evaluando en test y guardando el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.82      0.85      0.83       257\n",
      "        pos       0.83      0.80      0.82       243\n",
      "\n",
      "avg / total       0.83      0.83      0.83       500\n",
      "\n",
      "[[218  39]\n",
      " [ 48 195]]\n"
     ]
    }
   ],
   "source": [
    "print_eval(pipeline, X_test, y_test)\n",
    "from util import save_model\n",
    "save_model(pipeline, '2018-07-27_count_linearsvc_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Ahora qué?\n",
    "\n",
    "Algunas opciones:\n",
    "\n",
    "- Vectorización:\n",
    "  - ¿Explorar parámetros?\n",
    "  - ¿Probar TF-IDF?\n",
    "- Clasificador:\n",
    "  - ¿Explorar parámetros de la SVM?\n",
    "  - ¿Probar otros modelos de clasificación?\n",
    "\n",
    "Y más opciones:\n",
    "\n",
    "- Transformaciones:\n",
    "  - ¿Probar reducción de dimensionalidad?\n",
    "  - ¿Probar selección de features?\n",
    "\n",
    "Y más:\n",
    "\n",
    "- Análisis:\n",
    "  - ¿Buscar ejemplos conflictivos?\n",
    "  - ¿Hacer análisis de errores?\n",
    "  - ¿Hacer inspección del modelo?\n",
    "\n",
    "Y más:\n",
    "\n",
    "- Features:\n",
    "  - ¿Incorporar lexicones de palabras?\n",
    "  - ¿Word embeddings?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros del Vectorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.86      0.89      0.88       162\n",
      "        pos       0.86      0.83      0.85       138\n",
      "\n",
      "avg / total       0.86      0.86      0.86       300\n",
      "\n",
      "[[144  18]\n",
      " [ 23 115]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "        binary=True,\n",
    "        min_df=5, \n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 4),\n",
    "    )),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "from util import print_short_eval\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.91      0.89       162\n",
      "        pos       0.89      0.84      0.87       138\n",
      "\n",
      "avg / total       0.88      0.88      0.88       300\n",
      "\n",
      "[[148  14]\n",
      " [ 22 116]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "        binary=True,\n",
    "        min_df=5, \n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 4),\n",
    "    )),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "from util import print_short_eval\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
